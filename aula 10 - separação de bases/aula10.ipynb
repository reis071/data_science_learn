{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação de bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medindo a Qualidade do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que significa “qualidade do modelo”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualidade, nesse contexto, é o quão bem um modelo consegue fazer previsões corretas. Um modelo de boa qualidade é aquele que consegue generalizar, ou seja, que não apenas aprende os dados específicos de treino, mas que também faz boas previsões para novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de Bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que Separar Dados em Treino e Teste?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de treinar o modelo com todos os dados de uma vez, dividimos os dados em duas partes:\n",
    "\n",
    "Dados de Treino: para ensinar o modelo, ou seja, mostrar os exemplos para que ele aprenda.\n",
    "\n",
    "Dados de Teste: para ver como o modelo se comporta em dados novos que ele não viu durante o treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como isso ajuda?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao usar dados de teste, conseguimos ver se o modelo aprendeu padrões úteis ou se ele apenas “memorizou” os dados de treino, o que não é bom, pois o modelo não generaliza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro Quadrático Médio (MSE)\n",
    "\n",
    "Uma das formas mais comuns de medir a qualidade do modelo é através de uma métrica chamada Mean Squared Error (Erro Quadrático Médio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O que isso significa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O MSE nos diz, em média, o quanto as previsões do modelo estão “errando” em relação aos valores reais. O MSE calcula a média das diferenças entre valores reais e previstos, elevadas ao quadrado (para garantir que os erros positivos e negativos não se cancelem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine que temos um modelo que prevê o preço de casas e que fizemos algumas previsões. Vamos comparar os preços reais e previstos:\n",
    "\n",
    "Preços reais: [300,000; 450,000; 200,000]\n",
    "\n",
    "Preços previstos: [310,000; 460,000; 190,000]\n",
    "\n",
    "Aplicando a fórmula do MSE para esses valores, veremos o quanto em média o modelo está errando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "\n",
    "# Gerando dados de exemplo (só para simplificar)\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10)\n",
    "\n",
    "# Dividindo dados em treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Criando e treinando o modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o erro no treino e no teste\n",
    "y_pred_train = modelo.predict(X_train)\n",
    "y_pred_test = modelo.predict(X_test)\n",
    "\n",
    "# Calculando o MSE manualmente\n",
    "mse_train = np.mean((y_train - y_pred_train) ** 2)\n",
    "mse_test = np.mean((y_test - y_pred_test) ** 2)\n",
    "\n",
    "print(f\"MSE de Treino: {mse_train}\")\n",
    "print(f\"MSE de Teste: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erro de Treino vs. Erro de Teste e Ajustes do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando o Erro no Treino e no Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que comparar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando olhamos para o erro de treino e de teste, conseguimos entender como o modelo se comporta em relação aos dados que aprendeu e aos dados novos. Um bom modelo terá um erro de teste próximo ao de treino.\n",
    "O que pode dar errado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### que pode dar errado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se o erro de treino é muito baixo e o erro de teste é muito alto, isso pode indicar overfitting.\n",
    "\n",
    "Se o erro de treino é alto e o de teste também, isso pode indicar underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceitos de Overfitting e Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting (Superajuste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o modelo aprende demais os detalhes dos dados de treino, incluindo os “ruídos” e exceções. Assim, ele não consegue generalizar bem para novos dados, o que gera um erro alto no teste.\n",
    "\n",
    "Imagine que estamos ajustando uma linha em um gráfico de pontos. Um modelo com overfitting pode se parecer com uma linha extremamente ondulada, passando por quase todos os pontos, mas sem seguir o padrão geral dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfitting (Subajuste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o modelo é muito simples e não consegue capturar os padrões dos dados. Isso resulta em erros altos tanto no treino quanto no teste, pois ele não aprende nem memoriza os dados.\n",
    "\n",
    "Imagine o mesmo gráfico com pontos, mas agora o modelo é uma linha reta que passa pelo meio, ignorando que os dados são curvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Gerando dados de exemplo (só para simplificar)\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10)\n",
    "\n",
    "# Dividindo dados em treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Primeiro Script: Plotagem do Trade-Off entre Viés e Variância\n",
    "complexidade = np.arange(1, 15)\n",
    "erro_treino = [1/i for i in complexidade]  # Exemplo de erro de treino\n",
    "erro_teste = [0.05 * i + (1/i) for i in complexidade]  # Exemplo de erro de teste\n",
    "\n",
    "plt.plot(complexidade, erro_treino, label=\"Erro de Treino\")\n",
    "plt.plot(complexidade, erro_teste, label=\"Erro de Teste\")\n",
    "plt.xlabel(\"Complexidade do Modelo\")\n",
    "plt.ylabel(\"Erro\")\n",
    "plt.legend()\n",
    "plt.title(\"Trade-Off entre Viés e Variância\")\n",
    "plt.show()\n",
    "\n",
    "# Segundo Script: Comparação do MSE para Diferentes Graus de Modelos Polinomiais\n",
    "graus = [1, 3, 10]\n",
    "for grau in graus:\n",
    "    # Criando um pipeline para pré-processar os dados e aplicar regressão polinomial\n",
    "    modelo = make_pipeline(PolynomialFeatures(grau), LinearRegression())\n",
    "    modelo.fit(X_train, y_train)  # Treinando o modelo com os dados de treino\n",
    "\n",
    "    # Fazendo previsões para o treino e para o teste\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "\n",
    "    # Calculando o MSE manualmente\n",
    "    mse_train = np.mean((y_train - y_pred_train) ** 2)\n",
    "    mse_test = np.mean((y_test - y_pred_test) ** 2)\n",
    "\n",
    "    # Exibindo os resultados\n",
    "    print(f\"Grau {grau}:\")\n",
    "    print(f\"MSE de Treino: {mse_train}\")\n",
    "    print(f\"MSE de Teste: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viés e Variância e o Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo Viés e Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refere-se a erros que surgem quando um modelo é muito simples para capturar o padrão nos dados, levando a previsões imprecisas tanto nos dados de treino quanto nos de teste. Modelos com alto viés podem generalizar demais, ignorando detalhes específicos dos dados, levando ao underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refere-se a erros que surgem quando um modelo é muito complexo e se ajusta muito bem aos dados de treino, capturando até os ruídos. Isso significa que, embora o modelo tenha bom desempenho nos dados de treino, ele pode ter um desempenho ruim em novos dados, pois não consegue generalizar bem e fica vulnerável ao overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O “Trade-Off” entre Viés e Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Trade-off\" refere-se a uma situação em que é necessário fazer uma escolha entre dois fatores que são conflitantes: melhorar um deles implica sacrificar, em alguma medida, o outro. Em outras palavras, um trade-off é uma troca entre duas características que não podem ser maximizadas ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No trade-off entre viés e variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentar a complexidade do modelo tende a reduzir o viés, mas aumenta a variância, pois o modelo se ajusta demais aos dados de treino (overfitting).\n",
    "\n",
    "Reduzir a complexidade diminui a variância, mas aumenta o viés, pois o modelo se torna simples demais para capturar os padrões nos dados (underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é encontrar o ponto de equilíbrio em que o modelo não seja nem muito simples nem muito complexo, ou seja, um modelo que minimize o erro geral ao encontrar um bom trade-off entre viés e variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como equilibrar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segredo é escolher um modelo com uma complexidade “moderada” que reduza o erro no teste sem exagerar no ajuste aos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Importa a biblioteca matplotlib para plotagem de gráficos\n",
    "import numpy as np  # Importa a biblioteca NumPy para manipulação de arrays e cálculos matemáticos\n",
    "\n",
    "# Define a complexidade do modelo como uma sequência de valores de 1 a 14\n",
    "complexidade = np.arange(1, 15)\n",
    "\n",
    "# Simula o erro de treino inversamente proporcional à complexidade\n",
    "# Com modelos mais complexos, o erro de treino tende a diminuir\n",
    "erro_treino = [1/i for i in complexidade]  # Exemplo de erro de treino\n",
    "\n",
    "# Simula o erro de teste considerando tanto o viés quanto a variância\n",
    "# O erro de teste geralmente aumenta com a complexidade devido ao overfitting\n",
    "erro_teste = [0.05 * i + (1/i) for i in complexidade]  # Exemplo de erro de teste\n",
    "\n",
    "# Cria o gráfico para visualizar os erros\n",
    "plt.plot(complexidade, erro_treino, label=\"Erro de Treino\")  # Plota o erro de treino\n",
    "plt.plot(complexidade, erro_teste, label=\"Erro de Teste\")  # Plota o erro de teste\n",
    "\n",
    "# Define os rótulos dos eixos\n",
    "plt.xlabel(\"Complexidade do Modelo\")  # Rótulo para o eixo x\n",
    "plt.ylabel(\"Erro\")  # Rótulo para o eixo y\n",
    "\n",
    "# Adiciona uma legenda para identificar as curvas no gráfico\n",
    "plt.legend()\n",
    "\n",
    "# Define o título do gráfico\n",
    "plt.title(\"Trade-Off entre Viés e Variância\")  # Título do gráfico\n",
    "\n",
    "# Exibe o gráfico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
